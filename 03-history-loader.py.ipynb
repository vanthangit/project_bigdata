{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd31ce5-12b0-4466-bd31-f5416d2cffdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./01-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66be76b8-3035-417b-8b32-189ffb025675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SetupHelper():\n",
    "    def __init__(self, env):\n",
    "        Conf = Config()\n",
    "        self.landing_zone = Conf.base_data_path\n",
    "        self.catalog = env\n",
    "        self.db_name = Conf.db_name\n",
    "        self.initialized = False\n",
    "\n",
    "    def insert_date_table(self, csv_filename):  \n",
    "        from pyspark.sql.functions import col, to_timestamp\n",
    "        from pyspark.sql.types import IntegerType, ShortType, ByteType\n",
    "\n",
    "        try:\n",
    "            csv_path = f\"{self.landing_zone}/{csv_filename}\"\n",
    "            df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").csv(csv_path)\n",
    "            df_processed = df.select(\n",
    "                col(\"date_key\").cast(IntegerType()).alias(\"date_key\"),\n",
    "                to_timestamp(col(\"full_date\"), \"dd-MM-yy HH:mm\").alias(\"full_date\"),\n",
    "                col(\"day_of_week\").cast(ByteType()).alias(\"day_of_week\"),\n",
    "                col(\"day_num_in_month\").cast(ByteType()).alias(\"day_num_in_month\"),\n",
    "                col(\"day_num_overall\").cast(ShortType()).alias(\"day_num_overall\"),\n",
    "                col(\"day_name\").alias(\"day_name\"),\n",
    "                col(\"day_abbrev\").alias(\"day_abbrev\"),\n",
    "                col(\"weekday_flag\").alias(\"weekday_flag\"),\n",
    "                col(\"week_num_in_year\").cast(ByteType()).alias(\"week_num_in_year\"),\n",
    "                col(\"week_num_overall\").cast(ShortType()).alias(\"week_num_overall\"),\n",
    "                to_timestamp(col(\"week_begin_date\"), \"dd-MM-yy HH:mm\").alias(\"week_begin_date\"),\n",
    "                col(\"week_begin_date_key\").cast(IntegerType()).alias(\"week_begin_date_key\"),\n",
    "                col(\"month\").cast(ByteType()).alias(\"month\"),\n",
    "                col(\"month_num_overall\").cast(ShortType()).alias(\"month_num_overall\"),\n",
    "                col(\"month_name\").alias(\"month_name\"),\n",
    "                col(\"month_abbrev\").alias(\"month_abbrev\"),\n",
    "                col(\"quarter\").cast(ByteType()).alias(\"quarter\"),\n",
    "                col(\"year\").cast(ShortType()).alias(\"year\"),\n",
    "                col(\"yearmo\").cast(IntegerType()).alias(\"yearmo\"),\n",
    "                col(\"fiscal_month\").cast(ByteType()).alias(\"fiscal_month\"),\n",
    "                col(\"fiscal_quarter\").cast(ByteType()).alias(\"fiscal_quarter\"),\n",
    "                col(\"fiscal_year\").cast(ShortType()).alias(\"fiscal_year\"),\n",
    "                col(\"last_day_in_month_flag\").alias(\"last_day_in_month_flag\"),\n",
    "                to_timestamp(col(\"same_day_year_ago_date\"), \"dd-MM-yy HH:mm\").alias(\"same_day_year_ago_date\")\n",
    "            )\n",
    "\n",
    "            table_name = f\"{self.catalog}.{self.db_name}.date_lookup_bz\"\n",
    "            df_processed.write.mode(\"overwrite\").insertInto(table_name)\n",
    "            print(\"Done\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "setup = SetupHelper(\"dev\")\n",
    "setup.insert_date_table(\"date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b31d28ea-119b-4f0b-8f3c-b0b439374070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog `dev`; select * from `ecommerce_db`.`date_lookup_bz` limit 100;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8972107108947028,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03-history-loader.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
